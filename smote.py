# -*- coding: utf-8 -*-
"""smote.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MYIYyqlB-7N-2awQfoRXt8Co0-8d6EVi
"""

!pip install -U imbalanced-learn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import SMOTE
from google.colab import files
import io
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()



# Helper function to make plots prettier
def setup_plot(ax, title, xlabel, ylabel):
    ax.set_title(title, fontsize=15)
    ax.set_xlabel(xlabel, fontsize=12)
    ax.set_ylabel(ylabel, fontsize=12)
    ax.grid(True, linestyle='--', alpha=0.7)
    ax.legend()



def augment_and_visualize_smote():
    """
    Main function to upload data, apply SMOTE, visualize, and save results.
    """
    print("Ensure 'imbalanced-learn' is installed. If not, run: !pip install -U imbalanced-learn")

    # 1. Upload Dataset
    print("\nPlease upload your CSV dataset:")
    uploaded = files.upload()

    if not uploaded:
        print("No file uploaded. Exiting.")
        return

    file_name = list(uploaded.keys())[0]
    print(f"\nUploaded '{file_name}'")

    try:
        # Try common encodings if utf-8 fails
        try:
            df = pd.read_csv(io.BytesIO(uploaded[file_name]))
        except UnicodeDecodeError:
            print("UTF-8 decoding failed, trying latin1...")
            df = pd.read_csv(io.BytesIO(uploaded[file_name]), encoding='latin1')
    except Exception as e:
        print(f"Error reading CSV: {e}")
        return

    print("\nDataset head:")
    print(df.head())
    print(f"\nDataset shape: {df.shape}")
    print("\nColumn names:", df.columns.tolist())

    # 2. Get User Input for Columns
    target_column = ""
    while target_column not in df.columns:
        target_column = input(f"\nEnter the name of the TARGET variable column (e.g., 'target' or 'class'): ")
        if target_column not in df.columns:
            print(f"Column '{target_column}' not found. Please choose from: {df.columns.tolist()}")

    print(f"\nOriginal class distribution for '{target_column}':")
    print(df[target_column].value_counts())

    feature1_name = ""
    while feature1_name not in df.columns or feature1_name == target_column:
        feature1_name = input(f"\nEnter the name of the FIRST FEATURE for visualization: ")
        if feature1_name not in df.columns:
            print(f"Column '{feature1_name}' not found. Please choose from: {df.columns.tolist()}")
        elif feature1_name == target_column:
            print(f"Feature column cannot be the same as the target column ('{target_column}').")


    feature2_name = ""
    while feature2_name not in df.columns or feature2_name == target_column or feature2_name == feature1_name:
        feature2_name = input(f"\nEnter the name of the SECOND FEATURE for visualization: ")
        if feature2_name not in df.columns:
            print(f"Column '{feature2_name}' not found. Please choose from: {df.columns.tolist()}")
        elif feature2_name == target_column:
            print(f"Feature column cannot be the same as the target column ('{target_column}').")
        elif feature2_name == feature1_name:
            print(f"Second feature ('{feature2_name}') cannot be the same as the first feature ('{feature1_name}').")


    # Prepare data for SMOTE
    X_original = df.drop(target_column, axis=1)


    y_original = df[target_column]


    # Ensure features are numeric for SMOTE and plotting
    try:
        X_original[feature1_name] = pd.to_numeric(X_original[feature1_name])
        X_original[feature2_name] = pd.to_numeric(X_original[feature2_name])
    except ValueError as e:
        print(f"\nError: Features selected for visualization ('{feature1_name}', '{feature2_name}') must be numeric.")
        print(f"Details: {e}")
        print("Please ensure these columns contain only numbers or preprocess them accordingly.")
        return

    # Also ensure all features for SMOTE are numeric (or handle categorical appropriately)
    # For simplicity, this example assumes all X features are numeric or SMOTE will error.
    # A more robust solution would involve explicit encoding of categorical features.
    print("\nChecking if all features (excluding target) are numeric for SMOTE...")
    numeric_cols = X_original.select_dtypes(include=np.number).columns.tolist()
    non_numeric_cols = X_original.select_dtypes(exclude=np.number).columns.tolist()

    if non_numeric_cols:
        print(f"Warning: Non-numeric columns found in features: {non_numeric_cols}")
        print("SMOTE typically requires all features to be numeric.")
        print("Attempting to proceed, but this might cause errors or unexpected behavior.")
        print("Consider one-hot encoding or label encoding for categorical features before using SMOTE.")
        # If you want to strictly enforce numeric, you could add:
        # X_original = X_original[numeric_cols]
        # print(f"Using only numeric columns for SMOTE: {numeric_cols}")
        # if feature1_name not in numeric_cols or feature2_name not in numeric_cols:
        # print("Error: One of your selected visualization features is non-numeric and was dropped. Cannot proceed.")
        # return

    # 3. Visualization 1: Original Data
    print(f"\nPlotting original data using features '{feature1_name}' and '{feature2_name}'...")
    plt.figure(figsize=(10, 7))
    ax1 = plt.gca()
    sns.scatterplot(x=X_original[feature1_name], y=X_original[feature2_name], hue=y_original,
                    palette='viridis', alpha=0.7, ax=ax1)
    setup_plot(ax1, f'Original Data Distribution ({feature1_name} vs {feature2_name})',
               feature1_name, feature2_name)
    plt.tight_layout()
    plt.show()

    # 4. Apply SMOTE
    print("\nApplying SMOTE...")
    # Check for very small minority classes, which can cause issues with k_neighbors
    minority_class_count = y_original.value_counts().min()
    n_neighbors_smote = min(5, minority_class_count - 1) if minority_class_count > 1 else 1

    if n_neighbors_smote < 1:
        print(f"Warning: Minority class has only {minority_class_count} sample(s). SMOTE may not be effective or possible.")
        print("Skipping SMOTE application.")
        X_resampled, y_resampled = X_original.copy(), y_original.copy() # No change
    else:
        print(f"Using k_neighbors={n_neighbors_smote} for SMOTE due to minority class size.")
        smote = SMOTE(random_state=42, k_neighbors=n_neighbors_smote)
        try:
            X_resampled, y_resampled = smote.fit_resample(X_original, y_original)
            print("\nSMOTE applied successfully.")
            print("New class distribution:")
            print(y_resampled.value_counts())
        except Exception as e:
            print(f"Error during SMOTE: {e}")
            print("This can happen if features are not numeric or if a minority class is too small.")
            print("Proceeding with original data for the second plot and CSV output.")
            X_resampled, y_resampled = X_original.copy(), y_original.copy() # Revert to original if SMOTE fails

    num_original_samples = len(X_original)
    num_synthetic_samples = len(X_resampled) - num_original_samples

    # 5. Visualization 2: Augmented Data
    print(f"\nPlotting augmented data (original + {num_synthetic_samples} SMOTE points)...")
    plt.figure(figsize=(12, 8))
    ax2 = plt.gca()

    # Convert X_resampled to DataFrame to use feature names, if it's a NumPy array
    if isinstance(X_resampled, np.ndarray):
        X_resampled_df = pd.DataFrame(X_resampled, columns=X_original.columns)
    else: # it's already a DataFrame
        X_resampled_df = X_resampled

    # Plot original points
    # Ensure correct indexing for features in X_resampled_df
    # Original minority points
    original_minority_mask = (y_original == y_original.value_counts().idxmin())
    ax2.scatter(X_original.loc[original_minority_mask, feature1_name],
                X_original.loc[original_minority_mask, feature2_name],
                label=f'Original Minority ({y_original.value_counts().idxmin()})',
                alpha=0.5, c='blue', marker='o')

    # Original majority points
    original_majority_mask = (y_original == y_original.value_counts().idxmax())
    ax2.scatter(X_original.loc[original_majority_mask, feature1_name],
                X_original.loc[original_majority_mask, feature2_name],
                label=f'Original Majority ({y_original.value_counts().idxmax()})',
                alpha=0.5, c='navy', marker='o')

    # Plot synthetic points (these are appended by SMOTE)
    if num_synthetic_samples > 0:
        synthetic_X = X_resampled_df.iloc[num_original_samples:]
        # y_synthetic = y_resampled.iloc[num_original_samples:] # y_resampled should also be sliced

        ax2.scatter(synthetic_X[feature1_name], synthetic_X[feature2_name],
                    label='SMOTE Generated Points',
                    alpha=0.7, c='red', marker='^', s=50) # s for size

    setup_plot(ax2, f'Augmented Data ({feature1_name} vs {feature2_name})',
               feature1_name, feature2_name)
    plt.tight_layout()
    plt.show()

    # 6. Output Augmented Dataset as CSV
    df_resampled = pd.concat([pd.DataFrame(X_resampled_df), pd.Series(y_resampled, name=target_column)], axis=1)

    print("\nAugmented dataset head:")
    print(df_resampled.head())
    print(f"Augmented dataset shape: {df_resampled.shape}")

    augmented_file_name = f"augmented_{file_name}"
    df_resampled.to_csv(augmented_file_name, index=False)
    print(f"\nAugmented dataset saved as '{augmented_file_name}'.")
    print("Offering for download...")
    files.download(augmented_file_name)

    print("\nProcess completed!")

# Run the main function
if __name__ == "__main__":
    # This is just to ensure imblearn is available in Colab, you might run this in a separate cell first
    # !pip install -U imbalanced-learn
    augment_and_visualize_smote()